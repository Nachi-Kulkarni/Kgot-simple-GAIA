# Task 14: MCP Knowledge Base Builder - Complete Documentation

## Table of Contents
1. [Overview](#overview)
2. [Architecture](#architecture)  
3. [Installation & Setup](#installation--setup)
4. [Quick Start Guide](#quick-start-guide)
5. [API Reference](#api-reference)
6. [Advanced Features](#advanced-features)
7. [Performance Analytics](#performance-analytics)
8. [Integration Guide](#integration-guide)
9. [Configuration](#configuration)
10. [Troubleshooting](#troubleshooting)
11. [Examples](#examples)

---

## Overview

The **MCP Knowledge Base Builder** is an advanced implementation of Task 14 from the Enhanced Alita-KGoT system, designed to create and manage a comprehensive knowledge base of Model Control Protocol (MCP) tools using RAG-MCP Section 3.2 external vector index design principles.

### Key Features

- ðŸŽ¯ **RAG-MCP Section 3.2 Framework**: External vector index architecture with multi-modal embeddings
- ðŸ”„ **Intelligent Curation**: LangChain-based agents for automatic quality assessment and optimization
- ðŸ“Š **Performance Tracking**: RAG-MCP Section 4 experimental metrics with SQLite storage
- ðŸ” **Semantic Search**: Multi-modal vector search with capability-aware indexing
- âš¡ **Incremental Updates**: Version control, change tracking, and dependency management
- ðŸ“ˆ **Analytics**: Comprehensive knowledge base health monitoring and insights
- ðŸ”— **Integration**: Seamless connection with existing RAG-MCP Engine architecture

### Research Foundation

Implementation based on:
- **RAG-MCP Section 3.2**: External vector index design principles
- **RAG-MCP Section 4**: Experimental metrics for performance optimization
- **Pareto Principle**: High-value MCP curation following 80/20 optimization
- **LangChain Integration**: User's hard rule for agent development

---

## Architecture

### Core Components

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    MCP Knowledge Base Builder                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ MCPKnowledgeBaseâ”‚  â”‚ EnhancedVectorStoreâ”‚  â”‚ MCPCuratorAgent â”‚ â”‚
â”‚  â”‚    (Main        â”‚  â”‚  (Multi-modal     â”‚  â”‚  (LangChain     â”‚ â”‚
â”‚  â”‚   Orchestrator) â”‚  â”‚   Embeddings)     â”‚  â”‚   Curation)     â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚           â”‚                      â”‚                      â”‚        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚MCPPerformance   â”‚  â”‚  EnhancedMCPSpec â”‚  â”‚ KnowledgeBase   â”‚ â”‚
â”‚  â”‚   Tracker       â”‚  â”‚   (Enhanced      â”‚  â”‚   Metrics       â”‚ â”‚
â”‚  â”‚ (SQLite Storage)â”‚  â”‚ Specifications)  â”‚  â”‚ (Health Score)  â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Data Flow

```
User Query â†’ Semantic Search â†’ Multi-Modal Embeddings â†’ Vector Similarity
     â†“              â†“                    â†“                    â†“
Analytics â† Performance â† Quality Curation â† MCP Selection â† Results
```

---

## Installation & Setup

### Prerequisites

```bash
# Required Python packages
pip install numpy faiss-cpu sentence-transformers langchain langchain-openai
pip install aiohttp aiosqlite pydantic

# Optional for enhanced performance
pip install faiss-gpu  # For GPU acceleration
```

### Environment Configuration

```bash
# Required environment variables
export OPENROUTER_API_KEY="your_openrouter_api_key"

# Optional configuration
export MCP_KB_CACHE_DIR="./cache/mcp_knowledge_base"
export MCP_KB_VECTOR_DIMENSIONS="1536"
export MCP_KB_SIMILARITY_THRESHOLD="0.7"
```

### Directory Structure

```
alita-kgot-enhanced/
â”œâ”€â”€ alita_core/
â”‚   â”œâ”€â”€ mcp_knowledge_base.py    # Main implementation
â”‚   â””â”€â”€ rag_mcp_engine.py        # Integration dependency
â”œâ”€â”€ cache/
â”‚   â””â”€â”€ mcp_knowledge_base/      # Auto-created cache directory
â”‚       â”œâ”€â”€ vectors/             # Vector indices
â”‚       â”œâ”€â”€ performance.db       # Performance metrics
â”‚       â””â”€â”€ mcp_registry.json    # MCP registry cache
â””â”€â”€ logs/
    â””â”€â”€ alita/
        â””â”€â”€ mcp_knowledge_base.log
```

---

## Quick Start Guide

### Basic Usage

```python
import asyncio
from alita_core.mcp_knowledge_base import create_enhanced_knowledge_base, EnhancedMCPSpec, MCPCategory

async def main():
    # Create and initialize knowledge base
    kb = await create_enhanced_knowledge_base()
    
    # Add a new MCP
    new_mcp = EnhancedMCPSpec(
        name="custom_data_processor",
        description="Custom data processing tool with ML capabilities",
        capabilities=["data_analysis", "machine_learning", "visualization"],
        category=MCPCategory.DATA_PROCESSING,
        tags=["custom", "ml", "analysis"],
        author="your_username"
    )
    
    success = await kb.add_mcp(new_mcp, auto_curate=True)
    print(f"MCP added: {success}")
    
    # Search for MCPs
    results = await kb.search_mcps(
        "analyze data and create visualizations",
        max_results=5,
        filter_category=MCPCategory.DATA_PROCESSING
    )
    
    for result in results:
        print(f"Found: {result['name']} (similarity: {result['similarity_score']:.3f})")
    
    # Get analytics
    analytics = await kb.get_knowledge_base_analytics()
    print(f"KB Health Score: {analytics['knowledge_base_metrics']['health_score']:.3f}")

if __name__ == "__main__":
    asyncio.run(main())
```

### Integration with Existing RAG-MCP Engine

```python
from alita_core.rag_mcp_engine import RAGMCPEngine
from alita_core.mcp_knowledge_base import integrate_with_existing_rag_engine

async def integrated_example():
    # Create RAG-MCP Engine
    rag_engine = RAGMCPEngine(
        openrouter_api_key="your_api_key",
        enable_pareto_optimization=True
    )
    await rag_engine.initialize()
    
    # Create integrated knowledge base
    kb = await integrate_with_existing_rag_engine(rag_engine)
    
    # Knowledge base now has access to existing MCP registry
    print(f"Imported {len(kb.mcp_registry)} MCPs from RAG-MCP Engine")
```

---

## API Reference

### Main Classes

#### MCPKnowledgeBase

The main orchestrator class implementing the complete knowledge base functionality.

```python
class MCPKnowledgeBase:
    def __init__(self, 
                 openrouter_api_key: Optional[str] = None,
                 vector_dimensions: int = 1536,
                 similarity_threshold: float = 0.7,
                 cache_directory: Optional[str] = None,
                 enable_multi_modal: bool = True,
                 enable_curation: bool = True,
                 rag_engine: Optional[RAGMCPEngine] = None)
```

**Key Methods:**

##### `async initialize() -> bool`

Initialize the knowledge base with all components and indices.

```python
kb = MCPKnowledgeBase(openrouter_api_key="your_key")
success = await kb.initialize()
```

##### `async add_mcp(mcp_spec: Union[EnhancedMCPSpec, Dict], auto_curate: bool = True) -> bool`

Add new MCP to knowledge base with optional intelligent curation.

```python
# Add from enhanced specification
success = await kb.add_mcp(enhanced_mcp_spec, auto_curate=True)

# Add from dictionary
mcp_dict = {
    "name": "example_tool",
    "description": "Example tool description",
    "capabilities": ["capability1", "capability2"],
    "category": MCPCategory.DEVELOPMENT
}
success = await kb.add_mcp(mcp_dict, auto_curate=True)
```

##### `async search_mcps(query: str, max_results: int = 5, filter_category: Optional[MCPCategory] = None, include_metadata: bool = True) -> List[Dict[str, Any]]`

Search MCPs using enhanced semantic search with multi-modal embeddings.

```python
results = await kb.search_mcps(
    "analyze CSV data and create charts",
    max_results=5,
    filter_category=MCPCategory.DATA_PROCESSING,
    include_metadata=True
)
```

**Returns:** List of dictionaries containing:
- `name`: MCP name
- `description`: MCP description
- `capabilities`: List of capabilities
- `category`: MCP category
- `quality_score`: Quality assessment score
- `pareto_score`: Pareto optimization score
- `similarity_score`: Search similarity score
- `performance_summary`: Performance metrics summary
- `search_metadata`: Detailed search metadata (if requested)

##### `async get_knowledge_base_analytics() -> Dict[str, Any]`

Get comprehensive analytics about knowledge base performance and health.

```python
analytics = await kb.get_knowledge_base_analytics()
```

**Returns:** Analytics dictionary with:
- `knowledge_base_metrics`: Core KB metrics
- `top_performing_mcps`: Top 10 performing MCPs
- `quality_distribution`: Quality score distribution
- `search_performance`: Search performance statistics
- `curation_statistics`: Curation agent statistics
- `initialization_time_ms`: Initialization time

#### EnhancedMCPSpec

Enhanced MCP specification with comprehensive metadata and performance tracking.

```python
@dataclass
class EnhancedMCPSpec:
    # Core specification
    name: str
    description: str
    capabilities: List[str]
    category: MCPCategory
    
    # Performance metrics
    usage_frequency: float = 0.0
    reliability_score: float = 0.0
    cost_efficiency: float = 0.0
    pareto_score: float = 0.0
    
    # Enhanced features
    version: str = "1.0.0"
    created_at: datetime = field(default_factory=datetime.now)
    updated_at: datetime = field(default_factory=datetime.now)
    author: str = "system"
    tags: List[str] = field(default_factory=list)
    dependencies: List[str] = field(default_factory=list)
    
    # Quality assessment
    quality_score: MCPQualityScore = MCPQualityScore.ACCEPTABLE
    validation_history: List[Dict[str, Any]] = field(default_factory=list)
    curation_notes: List[str] = field(default_factory=list)
    
    # Multi-modal embeddings
    text_embedding: Optional[np.ndarray] = None
    capability_embedding: Optional[np.ndarray] = None
    metadata_embedding: Optional[np.ndarray] = None
    composite_embedding: Optional[np.ndarray] = None
```

**Key Methods:**

##### `update_performance_metrics(success: bool, response_time_ms: float, cost: float = 0.0, user_rating: float = 0.0)`

Update performance metrics based on usage results.

```python
mcp_spec.update_performance_metrics(
    success=True,
    response_time_ms=150.0,
    cost=0.05,
    user_rating=4.5
)
```

##### `to_legacy_spec() -> MCPToolSpec`

Convert to legacy MCPToolSpec for backwards compatibility.

```python
legacy_spec = enhanced_spec.to_legacy_spec()
```

### Supporting Classes

#### MCPPerformanceTracker

SQLite-based performance metrics tracking with comprehensive analytics.

```python
class MCPPerformanceTracker:
    async def record_usage(self, mcp_name: str, operation_type: str, 
                          success: bool, response_time_ms: float,
                          cost: float = 0.0, user_rating: float = 0.0,
                          error_message: str = None, context: Dict[str, Any] = None)
    
    async def get_mcp_metrics(self, mcp_name: str, timeframe_days: int = 30) -> Dict[str, Any]
```

#### EnhancedVectorStore

Multi-modal vector storage and retrieval with FAISS and fallback support.

```python
class EnhancedVectorStore:
    async def generate_multi_modal_embeddings(self, mcp_spec: EnhancedMCPSpec) -> Dict[str, np.ndarray]
    
    async def enhanced_semantic_search(self, query: str, top_k: int = 5,
                                     search_modes: List[str] = None,
                                     filter_category: Optional[MCPCategory] = None) -> List[Tuple[str, float, Dict[str, Any]]]
```

#### MCPCuratorAgent

LangChain-based intelligent MCP curation with specialized tools.

```python
class MCPCuratorAgent:
    # Curation tools:
    # - Quality Assessment Tool
    # - Capability Analysis Tool  
    # - Pareto Evaluation Tool
    # - Duplicate Detection Tool
    # - Category Classification Tool
```

---

## Advanced Features

### Multi-Modal Embeddings

The knowledge base uses four types of embeddings for enhanced semantic search:

```python
embeddings = {
    'text': text_embedding,           # Description embedding
    'capability': capability_embedding, # Capabilities embedding
    'metadata': metadata_embedding,    # Metadata embedding
    'composite': composite_embedding   # Combined multi-modal embedding
}
```

### Quality Assessment System

Automatic quality scoring based on multiple factors:

```python
class MCPQualityScore(Enum):
    EXCELLENT = "excellent"      # 90-100% - Production ready
    GOOD = "good"               # 75-89% - Minor improvements needed
    ACCEPTABLE = "acceptable"   # 60-74% - Usable but needs enhancement
    POOR = "poor"              # 40-59% - Significant improvements needed
    UNACCEPTABLE = "unacceptable"  # 0-39% - Major rework required
```

### Performance Metrics

Comprehensive tracking following RAG-MCP Section 4 experimental metrics:

- **Success Rate**: Percentage of successful operations
- **Response Time**: Average completion time in milliseconds
- **Cost Efficiency**: Cost per operation optimization
- **User Satisfaction**: User rating aggregation
- **Health Score**: Overall MCP health assessment
- **Pareto Score**: Multi-dimensional optimization score

### Incremental Updates

Version-controlled updates with complete audit trail:

```python
@dataclass
class MCPChangeRecord:
    change_id: str
    mcp_name: str
    operation: MCPUpdateOperation  # CREATE, UPDATE, DELETE, BATCH_UPDATE, REINDEX
    changes: Dict[str, Any]
    reason: str
    author: str
    timestamp: datetime
    impact_assessment: Dict[str, Any]
```

---

## Performance Analytics

### Knowledge Base Health Score

Calculated based on three factors:

1. **Quality Distribution** (33%): Ratio of excellent quality MCPs
2. **Pareto Score Average** (33%): Average Pareto optimization score
3. **Category Coverage** (33%): Balanced distribution across categories

```python
health_score = (quality_ratio + avg_pareto_score + coverage_factor) / 3
```

### Search Performance Metrics

- **Average Query Time**: Time to process search queries
- **Index Build Time**: Time to build vector indices
- **Cache Hit Rate**: Efficiency of caching system
- **Embedding Generation Time**: Time for multi-modal embedding creation

### Curation Statistics

- **Quality Improvements**: MCPs improved through curation
- **Duplicate Detection**: Prevented duplicate additions
- **Category Corrections**: Automatic category adjustments
- **Capability Enhancements**: Enhanced capability descriptions

---

## Integration Guide

### With RAG-MCP Engine

```python
# Seamless integration
kb = await integrate_with_existing_rag_engine(rag_engine)

# Bidirectional updates
await kb.sync_with_rag_engine()  # Push updates to RAG engine
await kb.import_from_rag_engine()  # Pull updates from RAG engine
```

### With Alita MCP Brainstorming

```python
# Enhanced MCP recommendations
from alita_core.mcp_brainstorming import MCPBrainstormingEngine

brainstorming_engine = MCPBrainstormingEngine()
recommendations = await brainstorming_engine.get_recommendations(task_description)

# Automatically add high-quality recommendations
for rec in recommendations:
    if rec['quality_score'] >= 0.8:
        await kb.add_mcp(rec, auto_curate=True)
```

### Custom Integration Bridge

```python
class CustomMCPIntegration:
    def __init__(self, kb: MCPKnowledgeBase):
        self.kb = kb
    
    async def integrate_custom_source(self, source_data):
        """Custom integration logic"""
        for item in source_data:
            enhanced_spec = self._convert_to_enhanced_spec(item)
            await self.kb.add_mcp(enhanced_spec, auto_curate=True)
```

---

## Configuration

### Environment Variables

```bash
# Core configuration
OPENROUTER_API_KEY="your_openrouter_api_key"    # Required
MCP_KB_CACHE_DIR="./cache/mcp_knowledge_base"   # Optional
MCP_KB_VECTOR_DIMENSIONS="1536"                 # Optional
MCP_KB_SIMILARITY_THRESHOLD="0.7"               # Optional

# Performance tuning
MCP_KB_ENABLE_FAISS="true"                      # Optional
MCP_KB_ENABLE_MULTI_MODAL="true"                # Optional
MCP_KB_ENABLE_CURATION="true"                   # Optional
MCP_KB_MAX_CACHE_SIZE="10000"                   # Optional
```

### Configuration Object

```python
kb_config = {
    'openrouter_api_key': os.getenv('OPENROUTER_API_KEY'),
    'vector_dimensions': 1536,
    'similarity_threshold': 0.7,
    'cache_directory': './cache/mcp_knowledge_base',
    'enable_multi_modal': True,
    'enable_curation': True,
    'enable_performance_tracking': True,
    'faiss_enabled': True,
    'logging_level': 'INFO'
}

kb = MCPKnowledgeBase(**kb_config)
```

---

## Troubleshooting

### Common Issues

#### 1. OpenRouter API Key Issues

```python
# Error: Missing or invalid API key
Error: OpenRouter API key not provided or invalid

# Solution:
export OPENROUTER_API_KEY="your_valid_api_key"
```

#### 2. Vector Index Build Failures

```python
# Error: Failed to build vector indices
Warning: Failed to build vector indices, continuing with limited functionality

# Solutions:
# 1. Check FAISS installation
pip install faiss-cpu

# 2. Verify embedding generation
kb.vector_store.embedding_client.test_connection()

# 3. Clear cache and rebuild
rm -rf ./cache/mcp_knowledge_base/vectors
await kb.vector_store.build_enhanced_indices(mcp_specs)
```

#### 3. Performance Issues

```python
# Slow search performance
# Solutions:
# 1. Enable FAISS for faster similarity search
export MCP_KB_ENABLE_FAISS="true"

# 2. Adjust similarity threshold
kb.vector_store.similarity_threshold = 0.6

# 3. Limit search scope
results = await kb.search_mcps(query, max_results=3)
```

#### 4. Database Lock Issues

```python
# SQLite database locked
# Solution: Close existing connections
await kb.performance_tracker.close_connections()
```

### Debug Mode

```python
import logging
logging.getLogger('MCPKnowledgeBase').setLevel(logging.DEBUG)

# Enable detailed logging
kb = MCPKnowledgeBase(
    openrouter_api_key="your_key",
    enable_debug_logging=True
)
```

### Health Checks

```python
async def health_check(kb: MCPKnowledgeBase):
    """Comprehensive health check"""
    analytics = await kb.get_knowledge_base_analytics()
    
    health_score = analytics['knowledge_base_metrics']['health_score']
    if health_score < 0.7:
        print(f"âš ï¸  Health score low: {health_score:.3f}")
    
    # Check component health
    vector_store_ok = await kb.vector_store.health_check()
    performance_tracker_ok = await kb.performance_tracker.health_check()
    
    print(f"Vector Store: {'âœ…' if vector_store_ok else 'âŒ'}")
    print(f"Performance Tracker: {'âœ…' if performance_tracker_ok else 'âŒ'}")
```

---

## Examples

### Example 1: Basic MCP Management

```python
async def basic_mcp_management():
    """Basic MCP addition, search, and analytics"""
    
    # Initialize knowledge base
    kb = await create_enhanced_knowledge_base()
    
    # Add custom MCP
    custom_mcp = EnhancedMCPSpec(
        name="data_scientist_toolkit",
        description="Comprehensive data science toolkit with ML models and visualization",
        capabilities=[
            "data_preprocessing", "statistical_analysis", "machine_learning",
            "data_visualization", "model_deployment", "feature_engineering"
        ],
        category=MCPCategory.DATA_PROCESSING,
        tags=["data_science", "machine_learning", "analytics", "visualization"],
        author="data_team",
        quality_score=MCPQualityScore.EXCELLENT
    )
    
    success = await kb.add_mcp(custom_mcp, auto_curate=True)
    print(f"MCP added successfully: {success}")
    
    # Search for data-related MCPs
    results = await kb.search_mcps(
        "analyze datasets and create machine learning models",
        max_results=5,
        filter_category=MCPCategory.DATA_PROCESSING
    )
    
    print(f"\nFound {len(results)} relevant MCPs:")
    for result in results:
        print(f"- {result['name']}: {result['similarity_score']:.3f} similarity")
        print(f"  Quality: {result['quality_score']}, Pareto: {result['pareto_score']:.3f}")
    
    # Get comprehensive analytics
    analytics = await kb.get_knowledge_base_analytics()
    kb_metrics = analytics['knowledge_base_metrics']
    
    print(f"\nðŸ“Š Knowledge Base Analytics:")
    print(f"Total MCPs: {kb_metrics['total_mcps']}")
    print(f"Health Score: {kb_metrics['health_score']:.3f}")
    print(f"Average Pareto Score: {kb_metrics['average_pareto_score']:.3f}")
    
    # Quality distribution
    quality_dist = analytics['quality_distribution']
    print(f"\nðŸŽ¯ Quality Distribution:")
    for quality, count in quality_dist.items():
        print(f"  {quality}: {count} MCPs")
```

### Example 2: Performance Tracking

```python
async def performance_tracking_example():
    """Demonstrate MCP performance tracking capabilities"""
    
    kb = await create_enhanced_knowledge_base()
    
    # Simulate MCP usage with performance tracking
    mcp_name = "web_scraper_enhanced"
    
    # Record successful usage
    await kb.performance_tracker.record_usage(
        mcp_name=mcp_name,
        operation_type="web_scraping",
        success=True,
        response_time_ms=245.0,
        cost=0.03,
        user_rating=4.5,
        context={"url": "https://example.com", "data_size": "2.5MB"}
    )
    
    # Record failed usage
    await kb.performance_tracker.record_usage(
        mcp_name=mcp_name,
        operation_type="web_scraping",
        success=False,
        response_time_ms=1200.0,
        error_message="Connection timeout",
        context={"url": "https://slow-site.com"}
    )
    
    # Get performance metrics
    metrics = await kb.performance_tracker.get_mcp_metrics(mcp_name)
    
    print(f"ðŸ“ˆ Performance Metrics for {mcp_name}:")
    print(f"Success Rate: {metrics['success_rate']:.1%}")
    print(f"Average Response Time: {metrics['avg_response_time_ms']:.1f}ms")
    print(f"Health Score: {metrics['health_score']:.3f}")
    print(f"Total Usage: {metrics['total_usage']} operations")
    
    # Update MCP spec with performance data
    if mcp_name in kb.mcp_registry:
        mcp_spec = kb.mcp_registry[mcp_name]
        mcp_spec.update_performance_metrics(
            success=True,
            response_time_ms=245.0,
            cost=0.03,
            user_rating=4.5
        )
        
        print(f"\nâœ… Updated {mcp_name} performance metrics")
```

### Example 3: Advanced Curation

```python
async def advanced_curation_example():
    """Demonstrate intelligent MCP curation capabilities"""
    
    # Initialize with curation enabled
    kb = MCPKnowledgeBase(
        openrouter_api_key=os.getenv('OPENROUTER_API_KEY'),
        enable_curation=True,
        enable_multi_modal=True
    )
    await kb.initialize()
    
    # Add MCP that needs curation
    low_quality_mcp = {
        "name": "basic_tool",
        "description": "Tool",  # Very brief description
        "capabilities": ["function"],  # Vague capability
        "category": "other",  # Unclear category
        "author": "",  # Missing author
        "tags": []  # No tags
    }
    
    print("ðŸ”§ Adding MCP with automatic curation...")
    success = await kb.add_mcp(low_quality_mcp, auto_curate=True)
    
    if success:
        # Check the curated version
        curated_mcp = kb.mcp_registry["basic_tool"]
        
        print(f"âœ… MCP curated successfully")
        print(f"Quality Score: {curated_mcp.quality_score.value}")
        print(f"Curation Notes: {curated_mcp.curation_notes}")
        
        # Show curation improvements
        if curated_mcp.curation_notes:
            print("\nðŸŽ¯ Curation Improvements:")
            for note in curated_mcp.curation_notes:
                print(f"  - {note}")
    
    # Get curation statistics
    if kb.curator_agent:
        curation_stats = kb.curator_agent.curation_stats
        print(f"\nðŸ“Š Curation Statistics:")
        print(f"Total Curated: {curation_stats.get('total_curated', 0)}")
        print(f"Quality Improvements: {curation_stats.get('quality_improvements', 0)}")
        print(f"Category Corrections: {curation_stats.get('category_corrections', 0)}")
```

### Example 4: Integration with RAG-MCP Engine

```python
async def rag_mcp_integration_example():
    """Demonstrate integration with existing RAG-MCP Engine"""
    
    from alita_core.rag_mcp_engine import RAGMCPEngine
    
    # Create RAG-MCP Engine
    rag_engine = RAGMCPEngine(
        openrouter_api_key=os.getenv('OPENROUTER_API_KEY'),
        enable_pareto_optimization=True,
        cache_directory="./cache/rag_mcp"
    )
    await rag_engine.initialize()
    
    # Create integrated knowledge base
    kb = await integrate_with_existing_rag_engine(rag_engine)
    
    print(f"ðŸ”— Integrated Knowledge Base created")
    print(f"Imported {len(kb.mcp_registry)} MCPs from RAG-MCP Engine")
    
    # Demonstrate bidirectional sync
    original_count = len(kb.mcp_registry)
    
    # Add new MCP to knowledge base
    new_mcp = EnhancedMCPSpec(
        name="knowledge_base_exclusive",
        description="MCP added directly to knowledge base",
        capabilities=["exclusive_function"],
        category=MCPCategory.DEVELOPMENT,
        pareto_score=0.85
    )
    
    await kb.add_mcp(new_mcp)
    
    # Sync back to RAG-MCP Engine (if supported)
    if hasattr(kb, 'sync_with_rag_engine'):
        await kb.sync_with_rag_engine()
        print("âœ… Synced new MCP back to RAG-MCP Engine")
    
    print(f"Total MCPs: {original_count} â†’ {len(kb.mcp_registry)}")
    
    # Demonstrate enhanced search with RAG-MCP integration
    results = await kb.search_mcps("web scraping and data extraction")
    
    print(f"\nðŸ” Enhanced Search Results:")
    for result in results:
        print(f"- {result['name']}: {result['similarity_score']:.3f}")
        if 'search_metadata' in result:
            search_meta = result['search_metadata']
            print(f"  Multi-modal scores: {search_meta.get('embedding_scores', {})}")
```

---

## Production Deployment

### Performance Optimization

```python
# Production configuration
production_config = {
    'vector_dimensions': 1536,
    'similarity_threshold': 0.75,  # Higher threshold for production
    'enable_multi_modal': True,
    'enable_curation': True,
    'cache_directory': '/var/cache/mcp_knowledge_base',
    'performance_tracking': True,
    'logging_level': 'INFO'
}

# Initialize for production
kb = MCPKnowledgeBase(**production_config)
await kb.initialize()

# Set up monitoring
async def monitor_kb_health():
    while True:
        analytics = await kb.get_knowledge_base_analytics()
        health_score = analytics['knowledge_base_metrics']['health_score']
        
        if health_score < 0.7:
            # Alert: Knowledge base health is degraded
            pass
        
        await asyncio.sleep(300)  # Check every 5 minutes
```

### Scaling Considerations

- **Vector Storage**: Use Redis for distributed vector caching
- **Performance Database**: PostgreSQL for high-volume metrics
- **Load Balancing**: Multiple knowledge base instances
- **Caching**: Implement distributed caching for search results

---

## Contributing

### Development Setup

```bash
# Clone and setup development environment
git clone <repository>
cd alita-kgot-enhanced
pip install -r requirements.txt

# Setup pre-commit hooks
pre-commit install

# Run tests
python -m pytest tests/test_mcp_knowledge_base.py -v
```

### Code Standards

- Follow existing code style and JSDoc3 comment standards
- Add comprehensive Winston logging for all operations
- Include type hints and detailed docstrings
- Write unit tests for new functionality

### Testing

```bash
# Run comprehensive tests
python test_mcp_knowledge_base.py

# Performance benchmarks
python benchmark_mcp_knowledge_base.py
```

---

## Status

**âœ… Production Ready** - Comprehensive implementation with:

- Full RAG-MCP Section 3.2 compliance
- Advanced multi-modal embeddings
- Intelligent LangChain-based curation
- Complete performance tracking
- Extensive documentation and examples
- Production-ready error handling and logging

**Version**: 1.0.0  
**Last Updated**: December 2024  
**Implementation**: Task 14 Complete âœ… 